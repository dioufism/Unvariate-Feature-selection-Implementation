{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "In this homework assignment, you will implement a univariate feature selection method. \n",
    "\n",
    "You will be given a toy dataset called 'Car Evaluation Data Set' (see: http://archive.ics.uci.edu/ml/datasets/Car+Evaluation for details).\n",
    "You are not required to, but advised to test your code with the toy dataset, or any other dataset that contains categorical variables.\n",
    "\n",
    "The given dataset contains six descriptive features and a target variable. Each of those are ordinal scale, categorical variables. The name of the target feature is 'evaluation'. \n",
    "\n",
    "Note here that you are expected to write your own code, so DO NOT COPY AND PASTE CODE OR USE LIBRARY FUNCTIONS. The goal of the homework is not to see if you can call library functions but to have you practice with the impurity measures and feature selection techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety evaluation\n",
       "0  vhigh  vhigh     2       2    small    low      unacc\n",
       "1  vhigh  vhigh     2       2    small    med      unacc\n",
       "2  vhigh  vhigh     2       2    small   high      unacc\n",
       "3  vhigh  vhigh     2       2      med    low      unacc\n",
       "4  vhigh  vhigh     2       2      med    med      unacc"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf = pd.read_csv('careval.csv')\n",
    "edf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      "buying        1728 non-null object\n",
      "maint         1728 non-null object\n",
      "doors         1728 non-null object\n",
      "persons       1728 non-null object\n",
      "lug_boot      1728 non-null object\n",
      "safety        1728 non-null object\n",
      "evaluation    1728 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "edf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will create a method called IUFS (impurity-based univariate feature selection), which will select the most informative features with a univariate feature selection schema. This feature selection method will take the dataset, name of the target variable, number of features to be selected (k) and the measure of impurity as an input, and will output the names of k best features based on the information gain. You are expected to implement information gain, entropy and Gini index functions. Note here that this will be a univariate selection, which means that you need to test the features individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(target_col):\n",
    "    p_x = target_col.value_counts(normalize = True)\n",
    "    return -np.sum( p_x * np.log2(p_x))\n",
    "    \n",
    "entropy(edf['doors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(target_col):\n",
    "    #count of the unique elements in the specified column\n",
    "    elements,counts = np.unique(target_col,return_counts = True)\n",
    "    #calculatign the entropy using the formula and looping thru the elements to perform operation\n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy\n",
    "pass\n",
    "entropy(edf['doors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004734848484848485"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini_index(feature, dataset):\n",
    "    # count all samples at split point\n",
    "    n_instances = float(sum([len(element) for element in feature]))\n",
    "    # sum weighted Gini index for each faeture\n",
    "    gini = 0.0\n",
    "    for element in feature:\n",
    "        size = float(len(element))\n",
    "# check if we are dividing by zero in case we have a empty column\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # score the group based on the score for each class\n",
    "        for row in dataset:\n",
    "            p = [row[-1] for row in element].count(row) / size\n",
    "            score += p * p\n",
    "# weight the group score by its relative size\n",
    "        gini = np.sum ( (1.0 - score) * (size / n_instances) )\n",
    "    return gini\n",
    "\n",
    "gini_index(edf['lug_boot'], edf ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini(target_col):\n",
    "        p_x = target_col.value_counts(normalize = True)\n",
    "        return  np. sum( 1 - p_x)\n",
    "gini(edf['buying'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09644896916961376"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def InfoGain(data,split_col,target_col=\"class\"):\n",
    "       \n",
    "    #entropy of the entire dataset\n",
    "    total_entropy = entropy(data[target_col])\n",
    "    \n",
    "    \n",
    "    #Calculate the values and the corresponding counts for the split attribute \n",
    "    values,counts= np.unique(data[split_col],return_counts=True)\n",
    "    \n",
    "    #Calculate the weighted entropy\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_col]==values[i]).dropna()[target_col]) for i in range(len(values))])\n",
    "    \n",
    "    #evaluation of the information gain\n",
    "    Information_Gain = total_entropy - Weighted_Entropy\n",
    "    return Information_Gain\n",
    "\n",
    "InfoGain(edf,'buying', 'evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IUFS(target, dataset, k, measure='entropy'):\n",
    "    \"\"\"Finds k most informative features in the given dataset based on the target variable\n",
    "        using information gain with the selected measure.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    k: int\n",
    "        number of features to return, must be less than or equal to number of descriptive features in dataset.\n",
    "        in other words, 0 < k < len(dataset.columns).\n",
    "    measure: str, 'entropy' or 'gini'\n",
    "        measure of impurity\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        returns a list of k feature names, selected based on univariate selection schema\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    pass\n",
    "\n",
    "# IUFS('evaluation', edf, 2, measure='entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "Improve the IUFS by including an option for gain ratio. Gain ratio is an alternative to information gain and can be used with either of the Gini index or entropy measures.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GR(feature, target, dataset, measure):\n",
    "    \"\"\"Calculates the gain ratio of a feature for a given target variable and a dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature: str\n",
    "        name of the feature\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    measure: str ('entropy' or 'gini')\n",
    "        measure of impurity to be used\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        gain ratio for the feature in the dataset for a given target variable\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    pass\n",
    "\n",
    "\n",
    "# GR('buying','evaluation', edf, 'gini') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IUFS2(target, dataset, k, measure='entropy', gain='IG'):\n",
    "    \"\"\"Finds k most informative features in the given dataset based on the target variable\n",
    "        using information gain with the selected measure.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    k: int\n",
    "        number of features to return, must be less than or equal to number of descriptive features in dataset.\n",
    "        in other words, 0 < k < len(dataset.columns).\n",
    "    measure: str, 'entropy' or 'gini'\n",
    "        measure of impurity\n",
    "    gain: str, 'IG' or 'GR'\n",
    "        feature selection metric ('IG' for information gain, 'GR' for gain ratio)\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        returns a list of k feature names, selected based on univariate selection schema\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    pass\n",
    "\n",
    "# IUFS2('evaluation', edf, 2, measure='gini', gain='GR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
